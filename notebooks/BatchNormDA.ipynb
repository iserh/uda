{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm for Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ignite.distributed as idist\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from uda.models import UNet, UNetConfig\n",
    "from uda.datasets import CC359, CC359Config\n",
    "from uda.metrics import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████| 9/9 [00:01<00:00,  4.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 1, 115, 115])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cfg = CC359Config.from_file(\"../config/dataset.yaml\")\n",
    "dataset_cfg.patch_size = (64, 115, 115)\n",
    "\n",
    "dataset = CC359(dataset_cfg)\n",
    "dataset.setup()\n",
    "dataloader = dataset.val_dataloader(batch_size=4)\n",
    "\n",
    "y_true = dataset.val_split.tensors[1]\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = UNetConfig.from_file(\"../config/model.yaml\")\n",
    "# model = UNet.from_pretrained(\"/tmp/models/teacher/best_model.pt\").to(idist.device())\n",
    "model = UNet(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uda.trainer import SegEvaluator\n",
    "from ignite.handlers import EpochOutputStore\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from uda import pipe, sigmoid_round_output_transform, to_cpu_output_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 13:08:40,084 SegEvaluator INFO: Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814da8e4ac8f4bc493a671cf6f4b6cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (GE_3)[1/144]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 13:08:40,829 SegEvaluator INFO: Epoch[1] Complete. Time taken: 00:00:01\n",
      "2022-08-07 13:08:40,829 SegEvaluator INFO: Engine run complete. Time taken: 00:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2304, 1, 112, 112)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = SegEvaluator(model)\n",
    "ProgressBar(desc=f\"Eval ({dataset.config.vendor})\", persist=True).attach(evaluator)\n",
    "eos = EpochOutputStore(\n",
    "    output_transform=pipe(sigmoid_round_output_transform, to_cpu_output_transform)\n",
    ")\n",
    "eos.attach(evaluator, \"output\")\n",
    "\n",
    "evaluator.run(dataset.val_dataloader(16))\n",
    "preds, targets, data = [*zip(*evaluator.state.output)]\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "targets = torch.cat(targets).numpy()\n",
    "data = torch.cat(data).numpy()\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from typing import Any, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ignite.utils import to_onehot\n",
    "from patchify import unpatchify\n",
    "\n",
    "\n",
    "def reshape_to_volume(\n",
    "    data: Union[np.ndarray, torch.Tensor], dim: int, imsize: tuple[int, int, int], patch_size: Optional[tuple[int, int, int]]\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    # check if torch.Tensor (patchify uses numpy backend)\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.numpy()\n",
    "        output_type_tensor = True\n",
    "    else:\n",
    "        output_type_tensor = False\n",
    "\n",
    "    # unpatchify if data is patchified\n",
    "    if patch_size is not None:\n",
    "        # compute number of patches for each axis\n",
    "        n_patches = [axis_size // patch_size for axis_size, patch_size in zip(imsize, patch_size)]\n",
    "        print(n_patches)\n",
    "        cropped_patch_size = patch_size[:-dim] + data.shape[-dim:]  # if data was cropped due to down/upsampling inaccuracies\n",
    "        print(cropped_patch_size)\n",
    "        cropped_imsize = [ps * np for ps, np in zip(cropped_patch_size, n_patches)]\n",
    "        print(cropped_imsize)\n",
    "        batch_size = int(data.shape[0] // (np.prod(n_patches) * np.prod(imsize[:-dim])))\n",
    "        print(\"bs\", batch_size)\n",
    "        print(data.shape)\n",
    "        # subsume batch_size in first patch axis (z-axis)\n",
    "        data = data.reshape(batch_size * n_patches[0], *n_patches[1:], *cropped_patch_size)\n",
    "        print(data.shape)\n",
    "        # unpatchify (subsume batch_size in first image axis)\n",
    "        data = unpatchify(data, imsize=(batch_size * cropped_imsize[0], *cropped_imsize[1:]))\n",
    "    else:\n",
    "        cropped_imsize = imsize[:-dim] + data.shape[-dim:]\n",
    "\n",
    "    # extract batch_size in first axis\n",
    "    data = data.reshape(-1, *cropped_imsize)\n",
    "\n",
    "    return torch.from_numpy(data) if output_type_tensor else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2]\n",
      "(192, 112, 112)\n",
      "[192, 224, 224]\n",
      "bs 3\n",
      "(12, 1, 192, 112, 112)\n",
      "(3, 2, 2, 192, 112, 112)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 192, 224, 224)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vol = reshape_to_volume(preds.reshape(12, 1, 192, 112, 112), 3, dataset.imsize, dataset.patch_size)\n",
    "y_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2]\n",
      "(192, 112, 112)\n",
      "[192, 224, 224]\n",
      "bs 3\n",
      "(2304, 1, 112, 112)\n",
      "(3, 2, 2, 192, 112, 112)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 192, 224, 224)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vol = reshape_to_volume(preds, model_cfg.dim, dataset.imsize, dataset.patch_size)\n",
    "y_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 112, 112)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_predictions(model, dataloader) -> torch.Tensor:\n",
    "    model.to(idist.device())\n",
    "    preds = torch.cat(\n",
    "        [\n",
    "            model(x.to(idist.device())).sigmoid().round().cpu()\n",
    "            for x, _ in tqdm(dataloader, desc=\"Predicting\")\n",
    "        ]\n",
    "    )\n",
    "    model.cpu()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is trained on domain `A` and will now be evaluated on domain `B`\n",
    "\n",
    "Set the model to eval, as you would usually do when evaluating on a new domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uda.models.modules import center_crop_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa1dfd447ae4632af6b06881989ee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0497)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = get_predictions(model, dataloader)\n",
    "\n",
    "y_true = center_crop_nd(y_true, y_pred.shape[1:])\n",
    "dice_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the model to train and run the dataset once (still no gradients, no training - just running the model)\n",
    "\n",
    "Then we gonna get our predictions in eval mode again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "y_pred = get_predictions(model, dataloader)\n",
    "\n",
    "model.eval()\n",
    "y_pred = get_predictions(model, dataloader)\n",
    "\n",
    "dice_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results have improved a lot, only due to adapting the running stats of our BatchNorm to the new domain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9bcf43fd28070f79a517f81758659f69011f725cffd2c0832fff1c14c055eba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
